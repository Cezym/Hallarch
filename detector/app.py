"""
## System RAG z detekcjƒÖ halucynacji

Celem systemu jest wykrywanie potencjalnych halucynacji w odpowiedziach generowanych przez model jƒôzykowy 
w architekturze RAG. 
System implementuje cztery niezale≈ºne metody detekcji:


1. LLM-based Judge (detektor oparty na LLM)


Metoda wykorzystuje du≈ºy model jƒôzykowy jako sƒôdziego semantycznego, kt√≥ry ocenia, 
czy odpowied≈∫ zosta≈Ça wygenerowana wy≈ÇƒÖcznie na podstawie dostarczonego kontekstu.


1. Kontekst i odpowied≈∫ sƒÖ przekazywane do LLM w postaci promptu oceniajƒÖcego.
2. Model otrzymuje instrukcjƒô zwr√≥cenia **pojedynczej liczby z zakresu [0,1]**:

   * `0.0` ‚Äì odpowied≈∫ ca≈Çkowicie spoza kontekstu (halucynacja)
   * `1.0` ‚Äì odpowied≈∫ w pe≈Çni oparta na kontek≈õcie
3. W praktyce wynik jest interpretowany jako **confidence score zgodno≈õci z kontekstem**.



Zalety:

* Bardzo dobra ocena semantyczna i logiczna
* Radzi sobie z parafrazami i implikacjami
* Najlepsza metoda do wykrywania subtelnych halucynacji

Wady / fa≈Çszywe alarmy:
* Metoda niestabilna (zale≈ºna od promptu)
* Wra≈ºliwa na bias samego LLM

----------------------------------------------------------------
----------------------------------------------------------------

2. Semantic Similarity Detector (embedding-based)

Metoda opiera siƒô na za≈Ço≈ºeniu, ≈ºe odpowied≈∫ oparta na kontek≈õcie powinna byƒá semantycznie podobna do 
tego kontekstu w przestrzeni embedding√≥w.

1.Obliczane sƒÖ embeddingi: E_answer, E_context
2. Obliczana jest cosinusowa miara podobie≈Ñstwa: sim = cosine_similarity(E_answer, E_context)
3.Wynik jest mapowany na prawdopodobie≈Ñstwo halucynacji: hallucination_score = 1 - sim
    Zakres
    sim ‚Üí 1.0 ‚Üí niskie ryzyko halucynacji
    sim ‚Üí 0.0 ‚Üí wysokie ryzyko halucynacji

Zalety:
*Szybka i deterministyczna
*Dobrze dzia≈Ça przy d≈Çugich fragmentach
≈Åatwa do skalowania

Wady / fa≈Çszywe alarmy:
*Mo≈ºe fa≈Çszywie alarmowaƒá przy kr√≥tkich odpowiedziach
*Nie wykrywa logicznych sprzeczno≈õci
*Wra≈ºliwa na "rozmycie" embeddingu przy du≈ºych chunkach

----------------------------------------------------------------
----------------------------------------------------------------
3. Stochastic Consistency Checker (BERT stochastic checker)

Metoda bada stabilno≈õƒá odpowiedzi modelu przy wielokrotnym generowaniu odpowiedzi z losowo≈õciƒÖ (temperature > 0).

Za≈Ço≈ºenie: halucynacje sƒÖ niestabilne semantycznie i zmieniajƒÖ siƒô miƒôdzy pr√≥bkami.

1.Generowanych jest N odpowiedzi (N ‚â• 3) z losowo≈õciƒÖ.
2.Ka≈ºda para odpowiedzi jest por√≥wnywana za pomocƒÖ metryki BERTScore.
3.Obliczana jest ≈õrednia sp√≥jno≈õƒá semantyczna: consistency = mean(BERTScore(answer_i, answer_j))

Interpretacja:
Wysoka sp√≥jno≈õƒá ‚Üí odpowied≈∫ stabilna
Niska sp√≥jno≈õƒá ‚Üí mo≈ºliwa halucynacja

Zalety:
*Dobrze wykrywa "wymy≈õlane" fakty
*Niezale≈ºna od jawnego kontekstu

Wady / fa≈Çszywe alarmy:
*Bardzo kosztowna obliczeniowo
*Mo≈ºe fa≈Çszywie alarmowaƒá przy pytaniach otwartych
*Wymaga wielu wywo≈Ça≈Ñ modelu


----------------------------------------------------------------
----------------------------------------------------------------

4. Token Similarity Detector (lexical overlap)

Najprostsza metoda, oparta na pokryciu leksykalnym miƒôdzy odpowiedziƒÖ a kontekstem.


Algorytm:
1.Tokenizacja odpowiedzi i kontekstu
2.Obliczenie pokrycia token√≥w: coverage = |tokens_answer ‚à© tokens_context| / |tokens_answer|

Score halucynacji:
hallucination_score = 1 - coverage

Interpretacja
coverage ‚Üí 1.0 ‚Üí odpowied≈∫ oparta na kontek≈õcie
coverage ‚Üí 0.0 ‚Üí odpowied≈∫ spoza kontekstu

Zalety:
*Bardzo szybka

Wady / fa≈Çszywe alarmy:
*Bardzo wra≈ºliwa na parafrazy
*Nie dzia≈Ça dobrze dla synonim√≥w
*Mo≈ºe fa≈Çszywie alarmowaƒá przy streszczeniach

----------------------------------------------------------------
----------------------------------------------------------------


"""







import os
import streamlit as st

from backend import (
    load_pdf,
    chunk_text,
    RAG,
    rag_answer,
    detect_hallucinations,
)

# =========================
# PAGE CONFIG
# =========================

st.set_page_config(
    page_title="RAG + Hallucination Detection",
    layout="wide",
)

st.title("üìÑ RAG z detekcjƒÖ halucynacji (Ollama)")

# =========================
# SESSION STATE
# =========================

for key in ["chat_id", "rag", "context", "answer", "hallucinations"]:
    if key not in st.session_state:
        st.session_state[key] = None

if st.session_state.chat_id is None:
    st.session_state.chat_id = 0


# =========================
# NEW CHAT
# =========================

if st.button("üÜï New chat"):
    for k in ["rag", "context", "answer", "hallucinations"]:
        st.session_state[k] = None
    try:
        os.remove("temp.pdf")
    except FileNotFoundError:
        pass
    st.session_state.chat_id += 1
    st.rerun()


# =========================
# PDF UPLOAD
# =========================

uploaded = st.file_uploader(
    "Wrzuƒá dokument PDF",
    type=["pdf"],
    key=f"uploader_{st.session_state.chat_id}",
)

if uploaded:
    with open("temp.pdf", "wb") as f:
        f.write(uploaded.read())

    text = load_pdf("temp.pdf")
    chunks = chunk_text(text)
    st.session_state.rag = RAG(chunks)
    st.success(f"üìë Za≈Çadowano dokument ({len(chunks)} fragment√≥w)")


# =========================
# QUESTION FORM
# =========================

with st.form(key=f"qa_form_{st.session_state.chat_id}"):
    question = st.text_input(
        "Zadaj pytanie",
        key=f"question_{st.session_state.chat_id}",
    )
    send = st.form_submit_button("üì® Send")


# =========================
# RAG PIPELINE
# =========================

if send:
    if not st.session_state.rag:
        st.warning("Najpierw wgraj dokument PDF.")
    elif question and question.strip():
        with st.spinner("My≈õlƒô..."):
            context = st.session_state.rag.retrieve(question)
            answer = rag_answer(question, context)
            hallucinations = detect_hallucinations(
                question, answer, context
            )

        st.session_state.context = context
        st.session_state.answer = answer
        st.session_state.hallucinations = hallucinations


# =========================
# ANSWER + WARNINGS
# =========================

if st.session_state.answer:
    st.subheader("üß† Odpowied≈∫")
    st.write(st.session_state.answer)

    meta = st.session_state.hallucinations.get("_meta")
    if meta and meta.get("no_context"):
        st.warning("‚ö†Ô∏è " + meta["warning"])

    st.subheader("üö® Detekcja halucynacji")

    for key, det in st.session_state.hallucinations.items():
        if key == "_meta":
            continue

        score = float(det["score"])

        st.markdown(f"### {det['name']}")
        st.caption(det["description"])
        st.progress(int(score * 100))
        st.write(f"Prawdopodobie≈Ñstwo halucynacji: **{score:.2f}**")

        if score < 0.33:
            st.success("Niskie ryzyko halucynacji")
        elif score < 0.66:
            st.warning("≈örednie ryzyko halucynacji")
        else:
            st.error("Wysokie ryzyko halucynacji")

        st.divider()


# =========================
# CONTEXT VIEW
# =========================

if st.session_state.context:
    with st.expander("üìö U≈ºyty kontekst"):
        for c in st.session_state.context:
            st.markdown(f"> {c}")
