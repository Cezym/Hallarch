{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../data/processed/model_df_vote_classification_normalized.csv\")"
   ],
   "id": "5f41c1e312e2a5fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class_counts = df[\"voted_classified\"].value_counts()\n",
    "print(\"Rodzaj danej odpowiedzi i jej ilość:\")\n",
    "print(class_counts)\n",
    "\n",
    "class_percent = class_counts / len(df) * 100\n",
    "print(\"\\nRodzaj danej odpowiedzi i jej ilość procentowa:\")\n",
    "print(class_percent.round(2))"
   ],
   "id": "a6230f2b5e91557d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df[\"is_correct\"] = df[\"voted_classified\"].isin([\"Correct Answers\", \"Best Answer\"])\n",
    "\n",
    "accuracy_by_model = df.groupby(\"model\")[\"is_correct\"].mean()*100\n",
    "hallucination_rate = 100 - accuracy_by_model\n",
    "\n",
    "print(\"Precyzja danego modelu procentowo:\")\n",
    "print(accuracy_by_model.round(2))\n",
    "print(\"\\nIlość halucynacji danego modelu procentowo:\")\n",
    "print(hallucination_rate.round(2))"
   ],
   "id": "81c06363bd49d792"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "acc_by_lorem = (df.groupby(\"lorem_length\")[\"is_correct\"].mean() * 100).round(2)\n",
    "print(\"Procentowa ilość poprawnych odpowiedzi w zależności od ilości znaków lorem ipsum:\")\n",
    "print(acc_by_lorem)"
   ],
   "id": "91f4a4c6b5ce54d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "acc_by_prompt = (df.groupby(\"prompt_type\")[\"is_correct\"].mean() * 100).round(2)\n",
    "print(\"Procentowa ilość poprawnych odpowiedzi w zależności od podania danej odpowiedzi:\")\n",
    "print(acc_by_prompt)"
   ],
   "id": "c61a9bdf9115637e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "\n",
    "sns.barplot(x=accuracy_by_model.index, y=accuracy_by_model.values)\n",
    "plt.title(\"Ilość poprawnych odpowiedzi procentowo udzielonych przez dany model\")\n",
    "plt.ylabel(\"Ilość poprawnych odpowiedzi %\")\n",
    "plt.show()\n",
    "\n",
    "heat_data = df.pivot_table(index=\"model\", columns=\"lorem_length\",\n",
    "                           values=\"is_correct\", aggfunc=\"mean\")\n",
    "sns.heatmap(heat_data, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Ilość poprawnych odpowiedzi danego modelu vs długość lorem ipsum\")\n",
    "plt.show()"
   ],
   "id": "1cf6ac19f8efde81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "pivot_acc_prompt = df.pivot_table(index=\"model\",\n",
    "                           columns=\"prompt_type\",\n",
    "                           values=\"is_correct\",\n",
    "                           aggfunc=np.mean)\n",
    "print(pivot_acc_.round(3))"
   ],
   "id": "7502a530d159cd69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "\n",
    "sns.barplot(x=acc_by_prompt.index, y=acc_by_prompt.values,\n",
    "            palette=\"viridis\")\n",
    "plt.title(\"Ilość poprawnych odpowiedzi wg podanego typu odpowiedzi\")\n",
    "plt.ylabel(\"Średnia dokładność\")\n",
    "plt.xlabel(\"Podany typ odpowiedzi\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ],
   "id": "d5993a8e3d007612"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "stack = pd.crosstab(df[\"prompt_type\"], df[\"voted_classified\"])\n",
    "stack_norm = stack.div(stack.sum(axis=1), axis=0)\n",
    "\n",
    "stack_norm.plot(kind=\"bar\", stacked=True, colormap=\"Set3\")\n",
    "plt.title(\"Rozkład rodzaju odpowiedzi wg podanego typu odpowiedzi\")\n",
    "plt.ylabel(\"Udział procentowy\")\n",
    "plt.xlabel(\"Typ podanej odpowiedzi\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ],
   "id": "5c80dc48b4c7103f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sns.heatmap(pivot_acc_prompt, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Ilość poprawnych odpowiedzi danego modelu vs rodzaj podanej odpowiedzi\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.xlabel(\"Typ podanej odpowiedzi\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ],
   "id": "b9f92c013ca0af2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "pivot_acc_lorem = df.pivot_table(index=\"model\",\n",
    "                           columns=\"lorem_length\",\n",
    "                           values=\"is_correct\",\n",
    "                           aggfunc=np.mean)\n",
    "print(pivot_acc_lorem.round(3))"
   ],
   "id": "b839cabee4510ad2"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
